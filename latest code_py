import os
import time
import pandas as pd
import fitz  
import requests
import warnings
import hashlib
import logging
import json
import ast
from typing import Dict, List, Any
import glob
from pathlib import Path
from docx import Document
from docx.shared import Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.shared import OxmlElement, qn
import re

warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def getFilehash(file_path: str):
    """Generate SHA3-256 hash of a file"""
    with open(file_path, 'rb') as f:
        return hashlib.sha3_256(f.read()).hexdigest()

class HostedLLM:
    """Custom LLM class for hosted Llama model"""
    
    def __init__(self, endpoint: str):
        self.endpoint = endpoint
    
    def _call(self, prompt: str) -> str:
        """Make API call to hosted LLM"""
        try:
            prompt_template = f"""<|begin_of_text|><|start_header_id|>user<|end_header_id|>
{prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>
"""
            
            payload = json.dumps({
                "provider": "tgi",
                "deployment": "Llama 3.3 v1",
                "spec_version": 1,
                "input_text": prompt_template,
                "params": {"temperature": 0.1}
            })
            
            headers = {
                'token': '0e53d2cf9f724a94a6ca0a9c880fdee7',
                'Content-Type': 'application/json'
            }
            
            response = requests.post(
                url="https://llmgateway.crisil.local/api/v1/llm",
                headers=headers,
                data=payload,
                verify=False
            )
            
            print(f"Response Status: {response.status_code}")
            if response.status_code != 200:
                return f"LLM Call Failed: HTTP {response.status_code} - {response.text}"
            
            response_v = ast.literal_eval(response.text)
            resp_o = response_v['output']
            output = str(resp_o).replace(prompt_template, "")
            return output.strip()
            
        except requests.exceptions.RequestException as e:
            return f"LLM Call Failed - Network Error: {e}"
        except json.JSONDecodeError as e:
            return f"LLM Call Failed - JSON Error: {e}"
        except KeyError as e:
            return f"LLM Call Failed - Missing Key: {e}"
        except Exception as e:
            return f"LLM Call Failed - General Error: {e}"

class PDFExtractor:
    """Class for extracting text from PDF files"""
    
    def extract_text_from_pdf(self, pdf_path: str) -> List[Dict[str, Any]]:
        """Extract text from each page of a PDF file"""
        start_time = time.time()
        try:
            doc = fitz.open(pdf_path)
            pages = []
            
            for page_num, page in enumerate(doc):
                text = page.get_text()
                pages.append({
                    "page_num": page_num + 1,
                    "text": text
                })
            
            # Explicitly close the document to free memory
            doc.close()
            logger.info(f"PDF text extraction took {time.time() - start_time:.2f} seconds")
            return pages
            
        except Exception as e:
            logger.error(f"PDF extraction error: {e}")
            raise

def mergeDocs(pdf_path: str, split_pages: bool = False) -> List[Dict[str, Any]]:
    """Merge PDF documents into a single context"""
    extractor = PDFExtractor()
    pages = extractor.extract_text_from_pdf(pdf_path)
    
    if split_pages:
        return [{"context": page["text"], "page_num": page["page_num"]} for page in pages]
    else:
        # Merge all pages into single context
        all_text = "\n".join([page["text"] for page in pages])
        return [{"context": all_text}]

class LlamaQueryPipeline:
    """Main pipeline class for querying PDF content with Llama"""
    
    def __init__(self, pdf_path: str, queries_csv_path: str = None, llm_endpoint: str = "https://llmgateway.crisil.local/api/v1/llm", previous_results_path: str = None):
        """Initialize the pipeline"""
        self.llm = HostedLLM(endpoint=llm_endpoint)
        self.docs = mergeDocs(pdf_path, split_pages=False)
        
        # Load queries from Excel or CSV (only if provided)
        if queries_csv_path:
            if queries_csv_path.endswith('.xlsx'):
                queries_df = pd.read_excel(queries_csv_path)
            else:
                queries_df = pd.read_csv(queries_csv_path)
            self.queries = queries_df["prompt"].tolist()
        else:
            self.queries = []
            
        self.pdf_path = pdf_path
        self.pdf_name = Path(pdf_path).stem  # Get filename without extension
        
        # Load previous results if provided
        self.previous_results = None
        if previous_results_path and os.path.exists(previous_results_path):
            self.previous_results = pd.read_csv(previous_results_path)

    def query_llama(self, maintain_conversation: bool = True, enable_chaining: bool = False) -> pd.DataFrame:
        """Query the Llama API for a list of queries using the provided context"""
        sys_prompt = f"""You are a financial analyst expert specializing in identifying red flags from earnings call transcripts and financial documents.

COMPLETE DOCUMENT TO ANALYZE:
{self.docs[0]["context"]}

Your task is to analyze the ENTIRE document above and identify ALL potential red flags.

CRITICAL OUTPUT FORMAT REQUIREMENTS:
- Number each red flag sequentially (1, 2, 3, etc.)
- Start each entry with: "The potential red flag you observed - [brief description]"
- Follow with "Original Quote:" and then the exact quote with speaker names
- Include page references where available: (Page X)
- Ensure comprehensive analysis of the entire document
- Do not miss any sections or concerning statements

EXAMPLE FORMAT:
1. The potential red flag you observed - Debt reduction is lower than expected  
Original Quote:  
"Vikrant Kashyap: Have you -- are you able to reduce any debt in quarter one in Middle East and India?  
Ramesh Kalyanaraman: So India, we are not reduced, but the cash balance has been increased to around INR75 crores, but we have not reduced any debt in Q1 in India and Middle East because Middle East we have not converted any showroom in Q1." (Page 9)  

2. The potential red flag you observed - Margin pressure/Competition intensifying/Cost inflation  
Original Quote:  
"Pulkit Singhal: Thank you for the opportunity and congrats on the good set of performance. Just the first question is really on the margins, which seems to have been elusive. I mean looking at the company for the last two years, we seem to be executing quite well in terms of store expansions and revenue growth and clearly delivering higher than expected there. But margin expansion just has been completely elusive.  
And I find it surprising your comment that while growing at 30% growth and 12% SSSG, I mean, which is quite healthy, you're still talking about high competitive intensity kind of quite contradictory that with such high growth rates, we have to invest so high. So can you talk about this a bit more? I mean we don't expect with lower revenue growth rates that you would not have to invest in the business. And it's only during a higher revenue growth that you expect margin expansion.  
Ramesh Kalyanaraman: Yes. So you're right. We are -- meaning somewhere we have missed out on the operating leverage for advertisements that's why I told you that even Q1, it was a miss. And regarding competition, I will tell you where in new markets, where we assume that we will not spend too much because the brand is already aware and the location is the only thing which has to be communicated.  
When you see the local players, regional players or the micro market players there becoming extremely active because of our showroom launch then we will have to increase the noise level there. Otherwise, we will lose our market share. And existing local players they increase their activity around our launch time. So that is where we also put more money so that we don't end up losing the market share or we don't end up taking out lesser from the competition." (Page 12-13)  

3. The potential red flag you observed - Debt high/Increase in borrowing cost  
Original Quote:  
"Vikrant Kashyap: My question is how are you going to address this? Because if you continue to grow at a higher level, but bottom line is not expanding related to the top line, it will going to impact your overall performance? So, what are the steps you are taking to improve the bottom line in the businesses  
Sanjay Raghuraman: Finance costs will be taken care because we told you when we convert stores, that money is going to reduce our debt. Okay. And again, FOCO, when you do FOCO showrooms, the margins will come down. And surely, that will have an impact on the gross margin. Okay. And interest, if you look at actually, the interest rates have been going up last year. So next year, that will be the base, right? So then again, we will not have this kind of issue is what we feel. So interest rates have been going up over the past year, one year, in that region.  
And we are also beginning to repay loans now because of conversion. So all put together, interest part will be taken care but other area where FOCO showrooms will surely reduce our margin. We cannot have the own store margin. So that should be the way we should look at it." (Page 9)

Continue this exact format for ALL red flags identified throughout the document.

"""
        
        prompt_template = """Question: {query}

Analyze the complete document and provide ALL red flags in the exact numbered format specified above. Be thorough and comprehensive - cover the entire document.

Answer:"""
        
        conversation_history = ""
        results = []
        previous_output = ""  # For prompt chaining
        
        for i, query in enumerate(self.queries, 1):
            start = time.perf_counter()
            
            try:
                if enable_chaining and i > 1 and previous_output:
                    chained_query = f"{query}\n\nPrevious context: {previous_output}"
                else:
                    chained_query = query
                
                if maintain_conversation and conversation_history:
                    full_prompt = f"{sys_prompt}\n{conversation_history}\n{prompt_template.format(query=chained_query)}"
                else:
                    full_prompt = f"{sys_prompt}\n{prompt_template.format(query=chained_query)}"
                
                response_text = self.llm._call(full_prompt)
                end = time.perf_counter()
                
                input_tokens = len(full_prompt.split())
                completion_tokens = len(response_text.split()) if response_text else 0
                
                usage = {
                    "query_id": i,
                    "query": query,
                    "chained_query": chained_query if enable_chaining else query,
                    "response": response_text,
                    "completion_tokens": completion_tokens,
                    "input_tokens": input_tokens,
                    "response_time": f"{end - start:.2f}"
                }
                
                # Update conversation history for next iteration
                if maintain_conversation:
                    conversation_history += f"\nQuestion: {chained_query}\nAnswer: {response_text}\n"
                
                # Store output for next chaining iteration
                if enable_chaining:
                    previous_output = response_text
                
            except Exception as e:
                end = time.perf_counter()
                
                usage = {
                    "query_id": i,
                    "query": query,
                    "chained_query": query,
                    "response": f"Error: {str(e)}",
                    "completion_tokens": None,
                    "input_tokens": None,
                    "response_time": f"{end - start:.2f}"
                }
                
                if enable_chaining:
                    previous_output = ""
            
            results.append(usage)
        
        return pd.DataFrame(results)

class CriteriaBasedRiskAnalyzer:
    """Direct criteria-based risk analysis"""
    
    def __init__(self, pdf_path: str, previous_year_data: str, llm_endpoint: str = "https://llmgateway.crisil.local/api/v1/llm"):
        self.llm = HostedLLM(endpoint=llm_endpoint)
        self.pdf_path = pdf_path
        self.pdf_name = Path(pdf_path).stem
        self.previous_year_data = previous_year_data
        
        # Extract PDF content for criteria analysis
        extractor = PDFExtractor()
        pages = extractor.extract_text_from_pdf(pdf_path)
        self.document_context = "\n".join([f"--- Page {page['page_num']} ---\n{page['text']}" for page in pages])
        
        # Define risk criteria prompts
        self.criteria_prompts = self._define_criteria_prompts()
    
    def _define_criteria_prompts(self) -> Dict[str, Dict[str, str]]:
        """Define specific prompts for each of the 15 risk criteria"""
        
        prompts = {
            # Balance Sheet Issues (6 criteria)
            "debt_increase": {
                "category": "Balance Sheet Issues",
                "prompt": f"""
Analyze the document for any mentions of debt increases, borrowings, or leverage changes.

Previous Year Data:
{self.previous_year_data}

Look for:
- Total debt amounts mentioned in current vs previous periods
- New borrowings or loan facilities
- Changes in debt-to-equity ratios
- Debt servicing concerns
- Any mentions of increased leverage or borrowing costs

Risk Classification:
- HIGH RISK: Debt increase ≥40% compared to previous period
- MEDIUM RISK: Debt increase 25-40% compared to previous period  
- LOW RISK: Debt increase <25% compared to previous period

Provide your analysis in this exact format:
RISK_LEVEL: [HIGH/MEDIUM/LOW/NONE]
EVIDENCE: [Specific quotes from the document with page numbers if available]
SUMMARY: [Brief explanation of the debt situation and key concerns]
""",
                "risk_thresholds": {"high": "≥40%", "medium": "25-40%", "low": "<25%"}
            },
            
            "provisioning": {
                "category": "Balance Sheet Issues",
                "prompt": f"""
Analyze the document for provisions, write-offs, or impairments.

Previous Year Data:
{self.previous_year_data}

Look for:
- Provisions for bad debts, loans, or investments
- Asset write-offs or impairments
- Restructuring provisions
- Legal or regulatory provisions
- Credit loss provisions

Risk Classification:
- HIGH RISK: Provisioning/write-offs >25% of current quarter's EBITDA
- MEDIUM RISK: Provisioning/write-offs 10-25% of current quarter's EBITDA
- LOW RISK: Provisioning/write-offs <10% of current quarter's EBITDA

Provide your analysis in this exact format:
RISK_LEVEL: [HIGH/MEDIUM/LOW/NONE]
EVIDENCE: [Specific quotes from the document with page numbers if available]
SUMMARY: [Brief explanation of provisioning situation and impact]
""",
                "risk_thresholds": {"high": ">25% of EBITDA", "medium": "10-25% of EBITDA", "low": "<10% of EBITDA"}
            },
            
            "asset_decline": {
                "category": "Balance Sheet Issues",
                "prompt": f"""
Analyze the document for asset value declines or impairments.

Previous Year Data:
{self.previous_year_data}

Look for:
- Asset value decreases
- Impairment charges
- Asset disposals at losses
- Property, plant & equipment write-downs
- Goodwill impairments

Risk Classification:
- HIGH RISK: Asset value falls ≥40% compared to previous period
- MEDIUM RISK: Asset value falls 25-40% compared to previous period
- LOW RISK: Asset value falls <25% compared to previous period

Provide your analysis in this exact format:
RISK_LEVEL: [HIGH/MEDIUM/LOW/NONE]
EVIDENCE: [Specific quotes from the document with page numbers if available]
SUMMARY: [Brief explanation of asset situation and reasons for decline]
""",
                "risk_thresholds": {"high": "≥40%", "medium": "25-40%", "low": "<25%"}
            },
            
            "receivable_days": {
                "category": "Balance Sheet Issues",
                "prompt": f"""
Analyze the document for accounts receivable or collection period changes.

Previous Year Data:
{self.previous_year_data}

Look for:
- Days sales outstanding (DSO)
- Collection period changes
- Receivables aging
- Bad debt provisions
- Customer payment delays

Risk Classification:
- HIGH RISK: Receivable days increase ≥40% compared to previous period
- MEDIUM RISK: Receivable days increase 25-40% compared to previous period
- LOW RISK: Receivable days increase <25% compared to previous period

Provide your analysis in this exact format:
RISK_LEVEL: [HIGH/MEDIUM/LOW/NONE]
EVIDENCE: [Specific quotes from the document with page numbers if available]
SUMMARY: [Brief explanation of receivables situation and collection concerns]
""",
                "risk_thresholds": {"high": "≥40%", "medium": "25-40%", "low": "<25%"}
            },
            
            "payable_days": {
                "category": "Balance Sheet Issues",
                "prompt": f"""
Analyze the document for accounts payable or payment period changes.

Previous Year Data:
{self.previous_year_data}

Look for:
- Days payable outstanding (DPO)
- Payment period extensions
- Supplier payment delays
- Working capital management
- Vendor relationship issues

Risk Classification:
- HIGH RISK: Payable days increase ≥40% compared to previous period
- MEDIUM RISK: Payable days increase 25-40% compared to previous period
- LOW RISK: Payable days increase <25% compared to previous period

Provide your analysis in this exact format:
RISK_LEVEL: [HIGH/MEDIUM/LOW/NONE]
EVIDENCE: [Specific quotes from the document with page numbers if available]
SUMMARY: [Brief explanation of payables situation and supplier impact]
""",
                "risk_thresholds": {"high": "≥40%", "medium": "25-40%", "low": "<25%"}
            },
            
            "debt_ebitda": {
                "category": "Balance Sheet Issues",
                "prompt": f"""
Analyze the document for debt-to-EBITDA ratio mentions or calculate from available data.

Previous Year Data:
{self.previous_year_data}

Look for:
- Debt-to-EBITDA ratios
- Leverage metrics
- Debt service coverage
- Covenant compliance
- Interest coverage ratios

Risk Classification:
- HIGH RISK: Debt/EBITDA >4x
- MEDIUM RISK: Debt/EBITDA 2-4x
- LOW RISK: Debt/EBITDA <2x

Provide your analysis in this exact format:
RISK_LEVEL: [HIGH/MEDIUM/LOW/NONE]
EVIDENCE: [Specific quotes from the document with page numbers if available]
SUMMARY: [Brief explanation of leverage situation and covenant concerns]
""",
                "risk_thresholds": {"high": ">4x", "medium": "2-4x", "low": "<2x"}
            },
            
            # P&L Issues (3 criteria)
            "revenue_decline": {
                "category": "P&L Issues",
                "prompt": f"""
Analyze the document for revenue or profitability declines.

Previous Year Data:
{self.previous_year_data}

Look for:
- Revenue growth/decline percentages
- Year-over-year or quarter-over-quarter comparisons
- Profitability changes
- EBITDA/Operating profit trends
- Same-store sales growth

Risk Classification:
- HIGH RISK: Revenue/profitability falls ≥40% compared to previous quarter
- MEDIUM RISK: Revenue/profitability falls 25-40% compared to previous quarter
- LOW RISK: Revenue/profitability falls <25% compared to previous quarter

Provide your analysis in this exact format:
RISK_LEVEL: [HIGH/MEDIUM/LOW/NONE]
EVIDENCE: [Specific quotes from the document with page numbers if available]
SUMMARY: [Brief explanation of revenue/profitability trends and underlying causes]
""",
                "risk_thresholds": {"high": "≥40%", "medium": "25-40%", "low": "<25%"}
            },
            
            "onetime_expenses": {
                "category": "P&L Issues",
                "prompt": f"""
Analyze the document for one-time expenses, exceptional items, or losses.

Previous Year Data:
{self.previous_year_data}

Look for:
- One-time charges
- Exceptional items
- Restructuring costs
- Legal settlements
- Asset write-offs
- Acquisition-related expenses

Risk Classification:
- HIGH RISK: One-time expenses >25% of current quarter's EBITDA
- MEDIUM RISK: One-time expenses 10-25% of current quarter's EBITDA
- LOW RISK: One-time expenses <10% of current quarter's EBITDA

Provide your analysis in this exact format:
RISK_LEVEL: [HIGH/MEDIUM/LOW/NONE]
EVIDENCE: [Specific quotes from the document with page numbers if available]
SUMMARY: [Brief explanation of one-time expenses and their nature]
""",
                "risk_thresholds": {"high": ">25% of EBITDA", "medium": "10-25% of EBITDA", "low": "<10% of EBITDA"}
            },
            
            "margin_decline": {
                "category": "P&L Issues",
                "prompt": f"""
Analyze the document for gross margin or operating margin declines.

Previous Year Data:
{self.previous_year_data}

Look for:
- Gross margin percentages
- Operating margin changes
- EBITDA margin trends
- Cost pressures
- Pricing power issues

Risk Classification:
- HIGH RISK: Margin decline >25% compared to previous quarter
- MEDIUM RISK: Margin decline 10-25% compared to previous quarter
- LOW RISK: Margin decline <10% compared to previous quarter

Provide your analysis in this exact format:
RISK_LEVEL: [HIGH/MEDIUM/LOW/NONE]
EVIDENCE: [Specific quotes from the document with page numbers if available]
SUMMARY: [Brief explanation of margin pressures and competitive dynamics]
""",
                "risk_thresholds": {"high": ">25%", "medium": "10-25%", "low": "<10%"}
            },
            
            # Liquidity Issues (2 criteria)
            "cash_balance": {
                "category": "Liquidity Issues",
                "prompt": f"""
Analyze the document for cash balance changes and liquidity concerns.

Previous Year Data:
{self.previous_year_data}

Look for:
- Cash and cash equivalents
- Cash flow statements
- Liquidity position
- Credit facility usage
- Working capital changes

Risk Classification:
- HIGH RISK: Cash balance falling >25% compared to previous period
- MEDIUM RISK: Cash balance falling 10-25% compared to previous period
- LOW RISK: Cash balance falling <10% compared to previous period

Provide your analysis in this exact format:
RISK_LEVEL: [HIGH/MEDIUM/LOW/NONE]
EVIDENCE: [Specific quotes from the document with page numbers if available]
SUMMARY: [Brief explanation of cash position and liquidity concerns]
""",
                "risk_thresholds": {"high": ">25%", "medium": "10-25%", "low": "<10%"}
            },
            
            "short_term_debt": {
                "category": "Liquidity Issues",
                "prompt": f"""
Analyze the document for short-term debt or current liability increases.

Previous Year Data:
{self.previous_year_data}

Look for:
- Short-term borrowings
- Current liabilities
- Working capital changes
- Debt maturity profiles
- Credit line utilization

Risk Classification:
- HIGH RISK: Short-term debt/current liabilities increase ≥40% compared to previous period
- MEDIUM RISK: Short-term debt/current liabilities increase 25-40% compared to previous period
- LOW RISK: Short-term debt/current liabilities increase <25% compared to previous period

Provide your analysis in this exact format:
RISK_LEVEL: [HIGH/MEDIUM/LOW/NONE]
EVIDENCE: [Specific quotes from the document with page numbers if available]
SUMMARY: [Brief explanation of short-term debt situation and maturity concerns]
""",
                "risk_thresholds": {"high": "≥40%", "medium": "25-40%", "low": "<25%"}
            },
            
            # Management Issues (1 criteria)
            "management_issues": {
                "category": "Management Issues",
                "prompt": f"""
Analyze the document for management-related concerns, strategy issues, or governance problems.

Look for:
- Management turnover or departures
- Key personnel changes
- CEO or CFO changes
- Execution challenges
- Strategic direction concerns
- Employee attrition
- Leadership effectiveness
- Board changes

Risk Classification:
- HIGH RISK: High management turnover, poor execution track record, high attrition
- MEDIUM RISK: Some management changes, some execution concerns, moderate attrition
- LOW RISK: Stable management, strong execution, low attrition

Provide your analysis in this exact format:
RISK_LEVEL: [HIGH/MEDIUM/LOW/NONE]
EVIDENCE: [Specific quotes from the document with page numbers if available]
SUMMARY: [Brief explanation of management stability and execution capabilities]
""",
                "risk_thresholds": {"high": "High turnover/poor execution", "medium": "Some concerns", "low": "Stable management"}
            },
            
            # Regulatory Issues (1 criteria)
            "regulatory_compliance": {
                "category": "Regulatory Issues",
                "prompt": f"""
Analyze the document for regulatory compliance issues, legal matters, or compliance violations.

Look for:
- Regulatory investigations
- Compliance violations
- Legal proceedings
- Regulatory warnings
- Audit findings
- License issues
- Fines or penalties
- Environmental issues

Risk Classification:
- HIGH RISK: Material non-compliance, repeated regulatory issues
- MEDIUM RISK: Some compliance issues, occasional warnings
- LOW RISK: No material compliance issues

Provide your analysis in this exact format:
RISK_LEVEL: [HIGH/MEDIUM/LOW/NONE]
EVIDENCE: [Specific quotes from the document with page numbers if available]
SUMMARY: [Brief explanation of regulatory status and compliance concerns]
""",
                "risk_thresholds": {"high": "Material non-compliance", "medium": "Some issues", "low": "No material issues"}
            },
            
            # Market Issues (1 criteria)
            "market_competition": {
                "category": "Market Issues",
                "prompt": f"""
Analyze the document for competitive pressures, market share changes, or industry challenges.

Look for:
- Competitive intensity
- Market share losses
- New entrants
- Pricing pressures
- Industry disruption
- Customer loss
- Product obsolescence

Risk Classification:
- HIGH RISK: High competitive intensity, material market share decline
- MEDIUM RISK: Some competitive pressure, some market share decline
- LOW RISK: Stable competitive position, stable/growing market share

Provide your analysis in this exact format:
RISK_LEVEL: [HIGH/MEDIUM/LOW/NONE]
EVIDENCE: [Specific quotes from the document with page numbers if available]
SUMMARY: [Brief explanation of competitive position and market dynamics]
""",
                "risk_thresholds": {"high": "High intensity/material decline", "medium": "Some pressure", "low": "Stable position"}
            },
            
            # Operational Issues (1 criteria)
            "operational_disruptions": {
                "category": "Operational Issues",
                "prompt": f"""
Analyze the document for operational disruptions, supply chain issues, or system failures.

Look for:
- Supply chain disruptions
- Production issues
- IT system failures
- Operational inefficiencies
- Process breakdowns
- Quality issues
- Capacity constraints

Risk Classification:
- HIGH RISK: Material operational disruptions, significant system failures
- MEDIUM RISK: Some operational issues, minor system problems
- LOW RISK: No material operational disruptions

Provide your analysis in this exact format:
RISK_LEVEL: [HIGH/MEDIUM/LOW/NONE]
EVIDENCE: [Specific quotes from the document with page numbers if available]
SUMMARY: [Brief explanation of operational stability and efficiency]
""",
                "risk_thresholds": {"high": "Material disruptions", "medium": "Some issues", "low": "No material disruptions"}
            }
        }
        
        return prompts
    
    def analyze_single_criteria(self, criteria_name: str) -> Dict[str, Any]:
        """Analyze document for a single risk criteria"""
        
        if criteria_name not in self.criteria_prompts:
            raise ValueError(f"Unknown criteria: {criteria_name}")
        
        criteria_info = self.criteria_prompts[criteria_name]
        
        # Create full prompt with document context
        full_prompt = f"""You are a financial risk analyst. Analyze the following document for the specific risk criteria mentioned below.

DOCUMENT CONTENT:
{self.document_context}

ANALYSIS TASK:
{criteria_info['prompt']}

Be thorough in your analysis and provide specific evidence from the document. If no relevant information is found, clearly state RISK_LEVEL: NONE and explain why.
"""
        
        start_time = time.time()
        response = self.llm._call(full_prompt)
        end_time = time.time()
        
        # Parse response to extract risk level
        risk_level = self._extract_risk_level(response)
        evidence = self._extract_evidence(response)
        summary = self._extract_summary(response)
        
        return {
            "criteria": criteria_name,
            "category": criteria_info["category"],
            "risk_level": risk_level,
            "evidence": evidence,
            "summary": summary,
            "full_response": response,
            "thresholds": criteria_info["risk_thresholds"],
            "response_time": f"{end_time - start_time:.2f}s"
        }
    
    def _extract_risk_level(self, response: str) -> str:
        """Extract risk level from LLM response"""
        response_upper = response.upper()
        
        # Primary parsing - look for exact format
        if "RISK_LEVEL: HIGH" in response_upper:
            return "HIGH"
        elif "RISK_LEVEL: MEDIUM" in response_upper:
            return "MEDIUM"
        elif "RISK_LEVEL: LOW" in response_upper:
            return "LOW"
        elif "RISK_LEVEL: NONE" in response_upper:
            return "NONE"
        else:
            # Fallback parsing
            if "HIGH RISK" in response_upper and "MEDIUM RISK" not in response_upper and "LOW RISK" not in response_upper:
                return "HIGH"
            elif "MEDIUM RISK" in response_upper and "HIGH RISK" not in response_upper:
                return "MEDIUM"
            elif "LOW RISK" in response_upper and "HIGH RISK" not in response_upper and "MEDIUM RISK" not in response_upper:
                return "LOW"
            else:
                return "UNCLEAR"
    
    def _extract_evidence(self, response: str) -> str:
        """Extract evidence section from response"""
        evidence_match = re.search(r'EVIDENCE:\s*(.+?)(?=SUMMARY:|$)', response, re.DOTALL | re.IGNORECASE)
        if evidence_match:
            return evidence_match.group(1).strip()
        return "No specific evidence extracted"
    
    def _extract_summary(self, response: str) -> str:
        """Extract summary section from response"""
        summary_match = re.search(r'SUMMARY:\s*(.+?), response, re.DOTALL | re.IGNORECASE)
        if summary_match:
            return summary_match.group(1).strip()
        return "No summary extracted"
    
    def analyze_all_criteria(self) -> pd.DataFrame:
        """Analyze document for all 15 risk criteria"""
        
        print(f"[CRITERIA ANALYSIS] Starting for {self.pdf_name}")
        print("=" * 70)
        
        results = []
        
        for i, criteria_name in enumerate(self.criteria_prompts.keys(), 1):
            print(f"[{i}/15] Analyzing: {criteria_name.ljust(25)}", end=" ")
            
            try:
                result = self.analyze_single_criteria(criteria_name)
                results.append(result)
                print(f"-> {result['risk_level'].ljust(8)} ({result['response_time']})")
                
                # Add small delay to avoid overwhelming the API
                time.sleep(0.5)
                
            except Exception as e:
                print(f"-> ERROR: {str(e)}")
                results.append({
                    "criteria": criteria_name,
                    "category": self.criteria_prompts[criteria_name]["category"],
                    "risk_level": "ERROR",
                    "evidence": "Error occurred during analysis",
                    "summary": f"Error: {str(e)}",
                    "full_response": f"Error: {str(e)}",
                    "thresholds": self.criteria_prompts[criteria_name]["risk_thresholds"],
                    "response_time": "0s"
                })
        
        return pd.DataFrame(results)
    
    def generate_criteria_summary(self, results_df: pd.DataFrame) -> Dict[str, Any]:
        """Generate summary report from criteria analysis"""
        
        # Count flags by risk level
        risk_counts = results_df['risk_level'].value_counts().to_dict()
        
        # Get high-risk flags
        high_risk_flags = results_df[results_df['risk_level'] == 'HIGH']
        
        # Extract summaries from high-risk flags
        high_risk_summaries = []
        for _, row in high_risk_flags.iterrows():
            summary = row['summary']
            if summary and summary != "No summary extracted":
                high_risk_summaries.append(f"{row['criteria'].replace('_', ' ').title()}: {summary}")
            else:
                high_risk_summaries.append(f"{row['criteria'].replace('_', ' ').title()}: High risk identified")
        
        return {
            "criteria_risk_counts": {
                "HIGH": risk_counts.get("HIGH", 0),
                "MEDIUM": risk_counts.get("MEDIUM", 0),
                "LOW": risk_counts.get("LOW", 0),
                "NONE": risk_counts.get("NONE", 0),
                "ERROR": risk_counts.get("ERROR", 0),
                "UNCLEAR": risk_counts.get("UNCLEAR", 0)
            },
            "criteria_high_risk_summaries": high_risk_summaries
        }

def extract_company_info_from_pdf(pdf_path: str, llm: HostedLLM) -> str:
    """Extract company name, quarter, and financial year from first page of PDF"""
    try:
        doc = fitz.open(pdf_path)
        first_page_text = doc[0].get_text()
        doc.close()
        
        # Limit text to first 2000 characters to avoid token limits
        first_page_text = first_page_text[:2000]
        
        prompt = f"""
You are a financial document analyst. Extract the company name, quarter, and financial year from the following text which is from the first page of an earnings call transcript or financial document.

Text from first page:
{first_page_text}

Please identify:
1. Company Name (full company name including Ltd/Limited/Inc etc.)
2. Quarter (Q1/Q2/Q3/Q4)
3. Financial Year (FY23/FY24/FY25 etc.)

Format your response as: [Company Name]-[Quarter][Financial Year]
Example: Reliance Industries Limited-Q4FY25

If you cannot find clear information, make the best estimate based on available data.

Response:"""
        
        response = llm._call(prompt)
        # Clean the response to get just the formatted string
        response_lines = response.strip().split('\n')
        for line in response_lines:
            if '-Q' in line and 'FY' in line:
                return line.strip()
        
        # Fallback - return first non-empty line
        return response_lines[0].strip() if response_lines else "Unknown Company-Q1FY25"
        
    except Exception as e:
        logger.error(f"Error extracting company info: {e}")
        return "Unknown Company-Q1FY25"

def parse_summary_by_categories(fourth_response: str) -> Dict[str, List[str]]:
    """Parse the 4th iteration summary response by categories"""
    categories_summary = {}
    
    # Split by ### headers
    sections = fourth_response.split('###')
    
    for section in sections:
        if not section.strip():
            continue
            
        lines = section.split('\n')
        category_name = ""
        bullets = []
        
        for line in lines:
            line = line.strip()
            if line and not line.startswith('*') and not line.startswith('-'):
                # This is likely the category name
                category_name = line.strip()
            elif line.startswith('*') or line.startswith('-'):
                # This is a bullet point
                bullet_text = line[1:].strip()  # Remove bullet symbol
                if bullet_text:
                    bullets.append(bullet_text)
        
        if category_name and bullets:
            categories_summary[category_name] = bullets
    
    return categories_summary

def process_complete_pipeline(pdf_path: str, queries_csv_path: str, previous_year_data: str, output_folder: str = "results"):
    """
    Process a single PDF through the complete pipeline:
    1. Run original 4 iterations
    2. Run criteria-based analysis
    3. Generate comprehensive Word report with both results
    """
    
    # Create output folder if it doesn't exist
    os.makedirs(output_folder, exist_ok=True)
    
    # Get PDF name without extension
    pdf_name = Path(pdf_path).stem
    
    print(f"\n{'='*80}")
    print(f"COMPLETE PIPELINE PROCESSING: {pdf_name}")
    print(f"{'='*80}")
    
    try:
        # ================== ORIGINAL 4 ITERATIONS ==================
        print("\n[PHASE 1] Running Original 4-Iteration Pipeline...")
        print("=" * 60)
        
        # ITERATION 1: Initial red flag identification
        print("Running 1st iteration - Initial Analysis...")
        pipeline_1st = LlamaQueryPipeline(
            pdf_path=pdf_path,
            queries_csv_path=queries_csv_path
        )
        
        # Run 1st iteration
        first_results_df = pipeline_1st.query_llama(maintain_conversation=True, enable_chaining=False)
        
        # Get first response for chaining
        first_response = first_results_df.iloc[0]['response']
        
        # ITERATION 2: Deduplication and cleanup
        print("Running 2nd iteration - Deduplication...")
        second_prompt = """Remove the duplicates from the above context. Also if the Original Quote and Keyword identifies is same remove them."""
        
        second_full_prompt = f"""You must answer the question strictly based on the below given context.

Context:
{pipeline_1st.docs[0]["context"]}

Previous Analysis: {first_response}

Based on the above analysis and the original context, please answer: {second_prompt}

Answer:"""
        
        second_response = pipeline_1st.llm._call(second_full_prompt)
        
        # ITERATION 3: Categorization of red flags
        print("Running 3rd iteration - Categorization...")
        third_prompt = """You are an expert in financial analysis tasked at categorizing the below identified red flags related to a company's financial health and operations. You need to categorize the red flags into following categories based on their original quotes and the identified keyword.

- Balance Sheet Issues: Red flags related to the company's assets, liabilities, equity, debt and overall financial position.
- P&L (Income Statement) Issues: Red flags related to the company's revenues, expenses, profits, and overall financial performance.
- Liquidity Issues: Concerns related to the company's ability to meet its short-term obligations, such as cash flow problems, debt repayment issues, or insufficient working capital.
- Management and Strategy related Issues: Concerns related to leadership, governance, decision-making processes, overall strategy, vision, and direction.
- Regulatory Issues: Concerns related Compliance with laws, regulations.
- Industry and Market Issues: Concerns related Position within the industry, market trends, and competitive landscape.
- Operational Issues: Concerns related Internal processes, systems, and infrastructure.

While categorizing the red flags strictly adhere to the following guidelines:
1. Please review the below red flags and assign each one to the most relevant category.
2. Do not loose information from the Original Quotes keep them as it is.
3. If a red flag could fit into multiple categories, please assign it to the one that seems most closely related, do not leave any flag unclassified or fit it into multiple categories.
4. While classifying, classify it in a such a way that the flags come under the categories along with their content. Strictly do not create a new category stick to what is mentioned above like an "Additional Red Flags", classify the flags in the above mentioned category only.
5. Do not repeat a category more than once in the output.

**Output Format**:
### Balance Sheet Issues
- [Red flag 1 with original quote]
- [Red flag 2 with original quote]

### P&L (Income Statement) Issues
- [Red flag 1 with original quote]
- [Red flag 2 with original quote]

### Liquidity Issues
- [Red flag 1 with original quote]
- [Red flag 2 with original quote]

### Management and Strategy related Issues
- [Red flag 1 with original quote]
- [Red flag 2 with original quote]

### Regulatory Issues
- [Red flag 1 with original quote]
- [Red flag 2 with original quote]

### Industry and Market Issues
- [Red flag 1 with original quote]
- [Red flag 2 with original quote]

### Operational Issues
- [Red flag 1 with original quote]
- [Red flag 2 with original quote]

Continue this format for all categories, ensuring every red flag from the previous analysis is categorized properly."""
        
        third_full_prompt = f"""You must answer the question strictly based on the below given context.

Context:
{pipeline_1st.docs[0]["context"]}

Previous Analysis: {second_response}

Based on the above analysis and the original context, please answer: {third_prompt}

Answer:"""
        
        third_response = pipeline_1st.llm._call(third_full_prompt)
        
        # ITERATION 4: Detailed summary generation
        print("Running 4th iteration - Summary Generation...")
        fourth_prompt = """Based on the categorized red flags from the previous analysis, provide a comprehensive and detailed summary of each category of red flags in bullet point format. Follow these guidelines:

1. **Retain all information**: Ensure that no details are omitted or lost during the summarization process
2. **Maintain a neutral tone**: Present the summary in a factual and objective manner, avoiding any emotional or biased language
3. **Focus on factual content**: Base the summary solely on the information associated with each red flag, without introducing external opinions or assumptions
4. **Include all red flags**: Incorporate every red flag within the category into the summary, without exception
5. **Balance detail and concision**: Provide a summary that is both thorough and concise, avoiding unnecessary elaboration while still conveying all essential information
6. **Incorporate quantitative data**: Wherever possible, include quantitative data and statistics to support the summary and provide additional context
7. **Category-specific content**: Ensure that the summary is generated based solely on the content present within each category
8. **Summary should be factual**: Avoid any subjective interpretations or opinions
9. **Use bullet points**: Each red flag should be summarized as a separate bullet point with key details and data points

Format the output exactly like this example:
### Balance Sheet Issues
* [Summary of red flag 1 with specific data points and factual information]
* [Summary of red flag 2 with specific data points and factual information]
* [Summary of red flag 3 with specific data points and factual information]

### P&L (Income Statement) Issues  
* [Summary of red flag 1 with specific data points and factual information]
* [Summary of red flag 2 with specific data points and factual information]
* [Summary of red flag 3 with specific data points and factual information]

### Liquidity Issues
* [Summary of red flag 1 with specific data points and factual information]
* [Summary of red flag 2 with specific data points and factual information]

### Management and Strategy related Issues
* [Summary of red flag 1 with specific data points and factual information]
* [Summary of red flag 2 with specific data points and factual information]

### Regulatory Issues
* [Summary of red flag 1 with specific data points and factual information]
* [Summary of red flag 2 with specific data points and factual information]

### Industry and Market Issues
* [Summary of red flag 1 with specific data points and factual information]
* [Summary of red flag 2 with specific data points and factual information]

### Operational Issues
* [Summary of red flag 1 with specific data points and factual information]
* [Summary of red flag 2 with specific data points and factual information]

Continue this format for all 7 categories. Each bullet point should be a concise summary that captures the key details of each red flag within that category, including relevant quantitative data where available."""
        
        fourth_full_prompt = f"""You must answer the question strictly based on the below given context.

Context:
{pipeline_1st.docs[0]["context"]}

Previous Analysis: {third_response}

Based on the above analysis and the original context, please answer: {fourth_prompt}

Answer:"""
        
        fourth_response = pipeline_1st.llm._call(fourth_full_prompt)
        
        # ================== CRITERIA-BASED ANALYSIS ==================
        print("\n[PHASE 2] Running Criteria-Based Analysis...")
        print("=" * 60)
        
        # Initialize criteria analyzer
        criteria_analyzer = CriteriaBasedRiskAnalyzer(pdf_path, previous_year_data)
        
        # Run criteria analysis
        criteria_results_df = criteria_analyzer.analyze_all_criteria()
        
        # Generate criteria summary
        criteria_summary = criteria_analyzer.generate_criteria_summary(criteria_results_df)
        
        # ================== COMPREHENSIVE REPORTING ==================
        print("\n[PHASE 3] Generating Comprehensive Reports...")
        print("=" * 60)
        
        # Extract company information
        print("Extracting company information...")
        company_info = extract_company_info_from_pdf(pdf_path, pipeline_1st.llm)
        print(f"Identified company: {company_info}")
        
        # Parse summary by categories from 4th iteration
        print("Parsing 4th iteration summary...")
        summary_by_categories = parse_summary_by_categories(fourth_response)
        
        # Create comprehensive Word document
        print("Creating comprehensive Word document...")
        word_doc_path = create_comprehensive_word_document(
            pdf_name=pdf_name,
            company_info=company_info,
            criteria_summary=criteria_summary,
            summary_by_categories=summary_by_categories,
            output_folder=output_folder
        )
        
        # Save all iteration results
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        all_iterations_results = pd.DataFrame({
            "pdf_name": [pdf_name, pdf_name, pdf_name, pdf_name],
            "iteration": [1, 2, 3, 4],
            "stage": [
                "Initial Analysis",
                "Deduplication",
                "Categorization", 
                "Summary Generation"
            ],
            "prompt": [
                first_results_df.iloc[0]['query'],
                second_prompt,
                third_prompt,
                fourth_prompt
            ],
            "response": [
                first_response,
                second_response,
                third_response,
                fourth_response
            ],
            "timestamp": [timestamp, timestamp, timestamp, timestamp]
        })
        
        # Save complete results
        iterations_output_file = os.path.join(output_folder, f"{pdf_name}_4iteration_results_{timestamp}.csv")
        all_iterations_results.to_csv(iterations_output_file, index=False)
        
        # Save criteria results
        criteria_output_file = os.path.join(output_folder, f"{pdf_name}_criteria_analysis_{timestamp}.csv")
        criteria_results_df.to_csv(criteria_output_file, index=False)
        
        print(f"\n{'='*80}")
        print(f"COMPLETE PIPELINE FINISHED: {pdf_name}")
        print(f"{'='*80}")
        print(f"4-Iteration Analysis: ✓ Completed")
        print(f"Criteria Analysis: ✓ Completed (15 criteria)")
        print(f"Flag Counts from Criteria Analysis: {criteria_summary['criteria_risk_counts']}")
        print(f"High Risk Flags: {len(criteria_summary['criteria_high_risk_summaries'])}")
        print(f"\nFiles Generated:")
        print(f"  • 4-Iteration Results: {os.path.basename(iterations_output_file)}")
        print(f"  • Criteria Analysis: {os.path.basename(criteria_output_file)}")
        print(f"  • Comprehensive Report: {os.path.basename(word_doc_path)}")
        
        return {
            "iterations_results": all_iterations_results,
            "criteria_results": criteria_results_df,
            "criteria_summary": criteria_summary,
            "summary_by_categories": summary_by_categories,
            "word_doc_path": word_doc_path
        }
        
    except Exception as e:
        print(f"Error processing {pdf_name}: {str(e)}")
        # Save error log
        error_df = pd.DataFrame({
            "pdf_name": [pdf_name],
            "error": [str(e)],
            "timestamp": [time.strftime("%Y%m%d_%H%M%S")]
        })
        error_file = os.path.join(output_folder, f"{pdf_name}_error_log.csv")
        error_df.to_csv(error_file, index=False)
        return None

def create_comprehensive_word_document(pdf_name: str, company_info: str, criteria_summary: Dict[str, Any],
                                     summary_by_categories: Dict[str, List[str]], output_folder: str) -> str:
    """Create a comprehensive Word document with both analyses"""
    
    # Create new document
    doc = Document()
    
    # Set document title
    title = doc.add_heading(company_info, 0)
    title.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    # Add analysis timestamp
    timestamp_para = doc.add_paragraph()
    timestamp_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
    timestamp_para.add_run(f"Analysis Date: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    # ================== CRITERIA-BASED FLAG DISTRIBUTION ==================
    flag_dist_heading = doc.add_heading('Flag Distribution (Criteria-Based Analysis):', level=1)
    flag_dist_heading.runs[0].bold = True
    
    # Create table for flag distribution
    table = doc.add_table(rows=len(criteria_summary['criteria_risk_counts']) + 1, cols=2)
    table.style = 'Table Grid'
    
    # Add table headers
    hdr_cells = table.rows[0].cells
    hdr_cells[0].text = 'Risk Level'
    hdr_cells[1].text = 'Count'
    for cell in hdr_cells:
        cell.paragraphs[0].runs[0].bold = True
    
    # Add table data
    row_idx = 1
    for risk_level, count in criteria_summary['criteria_risk_counts'].items():
        row_cells = table.rows[row_idx].cells
        row_cells[0].text = risk_level
        row_cells[1].text = str(count)
        row_idx += 1
    
    # Add space
    doc.add_paragraph('')
    
    # ================== HIGH RISK FLAGS SECTION ==================
    if criteria_summary['criteria_high_risk_summaries']:
        high_risk_heading = doc.add_heading('High Risk Flags (Criteria-Based Analysis):', level=1)
        high_risk_heading.runs[0].bold = True
        
        for flag in criteria_summary['criteria_high_risk_summaries']:
            p = doc.add_paragraph()
            p.style = 'List Bullet'
            p.add_run(flag)
    else:
        # If no high risk flags, add a note
        high_risk_heading = doc.add_heading('High Risk Flags (Criteria-Based Analysis):', level=1)
        high_risk_heading.runs[0].bold = True
        no_flags_para = doc.add_paragraph('No high risk flags identified.')
    
    # Add horizontal line separator
    doc.add_paragraph('_' * 80)
    
    # ================== 4TH ITERATION SUMMARY ==================
    summary_heading = doc.add_heading('Detailed Summary (4th Iteration Analysis)', level=1)
    summary_heading.runs[0].bold = True
    
    # Add categorized summary from 4th iteration
    for category, bullets in summary_by_categories.items():
        if bullets:  # Only add if there are bullets
            # Add category as subheading
            cat_heading = doc.add_heading(category, level=2)
            cat_heading.runs[0].bold = True
            
            # Add bullet points for this category
            for bullet in bullets:
                p = doc.add_paragraph()
                p.style = 'List Bullet'
                p.add_run(bullet)
            
            # Add space between categories
            doc.add_paragraph('')
    
    # ================== METHODOLOGY SECTION ==================
    doc.add_paragraph('_' * 80)
    
    methodology_heading = doc.add_heading('Analysis Methodology', level=1)
    methodology_heading.runs[0].bold = True
    
    method_para = doc.add_paragraph()
    method_para.add_run("This report combines two complementary analytical approaches:\n\n").bold = True
    
    method_para.add_run("1. 4-Iteration Pipeline Analysis: ").bold = True
    method_para.add_run("A comprehensive 4-step process involving initial red flag identification, deduplication, categorization into 7 key areas (Balance Sheet, P&L, Liquidity, Management & Strategy, Regulatory, Industry & Market, and Operational Issues), and detailed summary generation.\n\n")
    
    method_para.add_run("2. Criteria-Based Risk Analysis: ").bold = True
    method_para.add_run("Direct assessment of 15 specific financial risk criteria with structured HIGH/MEDIUM/LOW/NONE risk classifications based on quantitative thresholds and qualitative assessments.\n\n")
    
    method_para.add_run("The Flag Distribution and High Risk Flags sections above reflect the criteria-based analysis results, while the Detailed Summary section provides the comprehensive categorized findings from the 4-iteration analysis.")
    
    # Save document
    doc_filename = f"{pdf_name}_Comprehensive_Report.docx"
    doc_path = os.path.join(output_folder, doc_filename)
    doc.save(doc_path)
    
    return doc_path

def run_multiple_pdfs_complete_pipeline(pdf_folder_path: str, queries_csv_path: str, previous_year_data: str, output_folder: str = "results"):
    """
    Process multiple PDFs from a folder through the complete pipeline
    """
    
    # Create output folder if it doesn't exist
    os.makedirs(output_folder, exist_ok=True)
    
    # Get all PDF files from the folder
    pdf_files = glob.glob(os.path.join(pdf_folder_path, "*.pdf"))
    
    if not pdf_files:
        print(f"No PDF files found in {pdf_folder_path}")
        return
    
    print(f"\n{'='*80}")
    print(f"BATCH PROCESSING: {len(pdf_files)} PDF files found")
    print(f"Output folder: {output_folder}")
    print(f"{'='*80}")
    
    # Process each PDF
    successful_processing = []
    failed_processing = []
    
    for i, pdf_file in enumerate(pdf_files, 1):
        print(f"\n[{i}/{len(pdf_files)}] Processing: {os.path.basename(pdf_file)}")
        
        try:
            result = process_complete_pipeline(
                pdf_path=pdf_file,
                queries_csv_path=queries_csv_path,
                previous_year_data=previous_year_data,
                output_folder=output_folder
            )
            
            if result is not None:
                successful_processing.append({
                    "file": os.path.basename(pdf_file),
                    "high_risk_flags": len(result['criteria_summary']['criteria_high_risk_summaries']),
                    "total_criteria_flags": sum(result['criteria_summary']['criteria_risk_counts'].values())
                })
            else:
                failed_processing.append(os.path.basename(pdf_file))
                
        except Exception as e:
            print(f"Failed to process {os.path.basename(pdf_file)}: {str(e)}")
            failed_processing.append(os.path.basename(pdf_file))
    
    # Print batch summary
    print(f"\n{'='*80}")
    print(f"BATCH PROCESSING COMPLETED")
    print(f"{'='*80}")
    
    if successful_processing:
        print(f"\nSuccessfully processed {len(successful_processing)} files:")
        for result in successful_processing:
            print(f"  ✓ {result['file']} -> {result['high_risk_flags']} high-risk flags ({result['total_criteria_flags']} total)")
    
    if failed_processing:
        print(f"\nFailed to process {len(failed_processing)} files:")
        for file in failed_processing:
            print(f"  ✗ {file}")

def main_complete_pipeline():
    """Main function to run the complete pipeline"""
    
    pdf_folder_path = r"ola_pdf"
    queries_csv_path = r"EWS_prompts_v2.xlsx"      
    output_folder = r"ola_results_complete_pipeline"
    
    # Previous year data - you can modify this for each company
    previous_year_data = """
Previous reported Debt: 5,684 Cr (Mar-24)
Current quarter EBITDA: (525) Cr (Mar-25)
Previous reported asset value: 7,735 Cr (Mar-24)
Previous reported receivable days: 12 days (Mar-24)
Previous reported payable days: 112 days (Mar-24)
Previous reported revenue: 1,045 Cr (Dec-24)
Previous reported profitability: (460) Cr (Dec-24)
Previous reported operating margin: -44.00% (Dec-24)
Previous reported cash balance: 1,663 Cr (Mar-24)
Previous reported current liabilities: 1,071 Cr (Mar-24)
"""
    
    run_multiple_pdfs_complete_pipeline(
        pdf_folder_path=pdf_folder_path,
        queries_csv_path=queries_csv_path,
        previous_year_data=previous_year_data,
        output_folder=output_folder
    )

if __name__ == "__main__":
    print("Complete Financial Risk Analysis Pipeline")
    print("=" * 80)
    print("This script runs both approaches:")
    print("1. Original 4-Iteration Pipeline (Initial -> Deduplication -> Categorization -> Summary)")
    print("2. Criteria-Based Analysis (15 specific risk criteria)")
    print("3. Comprehensive Word Report with both results")
    print(f"\n{'='*80}")
    print("Starting complete pipeline...")
    
    # Run the complete pipeline
    main_complete_pipeline()
    
    print(f"\n{'='*80}")
    print("Complete pipeline finished!")
    print("Generated files:")
    print("  • 4-iteration results CSV")
    print("  • Criteria analysis CSV")
    print("  • Comprehensive Word reports with:")
    print("    - Flag counts from criteria analysis")
    print("    - High-risk summaries from criteria analysis")
    print("    - Detailed categorized summary from 4th iteration")
    print("    - Methodology explanation")
